# EM 算法学习小结

2023/11/14- april211

## 背景

机器学习课已经结课一段时间，还有一周左右的时间就要考试了。

我用的教材是 `Andrew Ng` 的 `CS229` 机器学习讲义，自己手里有李航老师的《统计学习方法》作为参考资料。

然后就这样一章一章地复习，还算顺利。但是当我复习到 EM 算法这一章的时候，发现《统计学习方法》关于 EM 算法的讲解很抽象（也许是我数学太菜……），推导过程与那本机器学习讲义有些许不同，导致理解难度比较高。

写这个小结，主要是梳理一下自己的推导过程，理顺 EM 算法的 idea 和整体逻辑，并且打通感性认识（简单示例计算）和严格公式推导之间的 gap。

## 阅读前注意

本文的主要讨论对象是 EM 算法的导出过程，内容以 `CS229` 机器学习讲义的 `Note 8: The EM algorithm` 为主，《统计学习方法》上的相关内容为辅。

本文会对 EM 算法的收敛性作简要的推导，但是并不会对 EM 算法的推广以及高斯混合模型进行讨论。

本文参考了大量的博客资料，将使用脚注一一列出。

## 导引：三硬币模型

在李航老师的书中，我们认识了三硬币模型是什么样的，以及使用 EM 算法估计三硬币模型参数（也就是三个硬币正面朝上的概率）的公式推导结果。

但是，书中并没有给出详细的推导过程。这里我给出一个知乎的链接[^1]，可以说把这块讲的很清楚了。

[^1]: HAORAN JIANG. EM算法与‘简单🌰’的三硬币模型[EB/OL]//菜园自留地. (2019-02-25)[2023-11-14]. https://zhuanlan.zhihu.com/p/57679630.

在这个模型中，

## “两硬币模型”的引入

这里我打算给出另外一个示例的公式推导过程，并且在此基础上理解 EM 算法的原理和一些细节。

由于这个示例仅仅涉及到两个硬币，并且在每次选定一枚硬币后，会多次重复地抛掷这枚选中的硬币，所以姑且叫它“两硬币模型”。

这个示例有许多博客讲解[^2] [^3]，他们讲得都很好！但是美中不足就是：都没有给出示例问题所对应的详细的公式推导过程，而是仅仅给出了数值计算过程。我个人认为，这样**没有将示例与公式推导紧密结合，不利于真正地理解 EM 算法**，所以有了写这篇文的想法。

[^2]: 阿泽. 【机器学习】EM——期望最大（非常详细）[EB/OL]//机器学习算法与自然语言处理. (2019-08-15)[2023-11-13]. https://zhuanlan.zhihu.com/p/78311644.

[^3]: 如何感性地理解EM算法？[EB/OL]//简书. (2017-03-30)[2023-11-13]. https://www.jianshu.com/p/1121509ac1dc.

从上面的简单介绍来看，这个模型与上面的三硬币模型显然是不同的。具体体现为两点：

1. 在两硬币模型中，**选择硬币 A 还是硬币 B 的准则是完全未知**的。这点是与三硬币模型最大的区别，因为在三硬币模型中，会首先根据第一枚硬币 C 的投掷结果来从剩下的两枚硬币 A 、B 中选择一枚硬币，而硬币 C 是有模型参数的（对应于它的先验概率）。这点会影响 EM 算法中 E 步的公式推导，至于在两硬币模型中，准则的未知性该如何处理，后面会讲到。

2. 正如前面所提到的，典型的三硬币模型中（以李航老师书中的示例为例），选定一枚硬币后，仅对这枚硬币进行一次投掷，所以中的结果个数就等于硬币 C 的投掷次数，也就是硬币 A、 B 的选择轮数；而在本文叙述的两硬币模型中，会对每一轮中选定的硬币进行**多次投掷**，所以我们可以获得的投掷结果个数将大于三硬币模型中的投掷结果个数。

接下来，我将给出“两硬币模型”的公式推导过程，并在必要处进行说明。

## “两硬币模型”的 EM 算法推导过程

假设在两硬币模型中，总共涉及到 $` A `$ 和 $` B `$ 两枚硬币。

现在，我们将进行 $` M `$ 轮次的实验（也就是选择 $` M `$ 次硬币），而每选择完一次硬币，就会重复地投掷这个硬币 $` N `$ 次。

每轮实验，我们都会获得一个样本 $` x^{(i)} `$，其中 $` i = 1, 2, ..., M `$，这个样本是一个 $` N `$ 维的向量，向量的每一个元素表示该轮投掷的其中一个结果。

例如，对于

